{
    "llama-3.2-1b-instruct": {
        "engine": "mlc",
        "modelName": "Llama-3.2-1b-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/llama-3.2-1b-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f16_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "pipeline": "text-generation"
    },
    "smollm2-135m-instruct": {
        "engine": "mlc",
        "modelName": "SmolLM2-135M-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/SmolLM2-135M-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f16_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "required_features": [
            "shader-f16"
        ],
        "overrides": {
            "context_window_size": 4096
        },
        "pipeline": "text-generation"
    },
    "smollm2-350m-instruct": {
        "engine": "mlc",
        "modelName": "SmolLM2-350M-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/SmolLM2-350M-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f16_1",
        "required_features": [
            "shader-f16"
        ],
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "pipeline": "text-generation"
    }
}